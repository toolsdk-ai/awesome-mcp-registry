{
  "type": "mcp-server",
  "packageName": "mcp-llm",
  "description": "Integrates with LlamaIndexTS to provide access to various LLM providers for code generation, documentation writing, and question answering tasks",
  "url": "https://github.com/sammcj/mcp-llm",
  "runtime": "node",
  "license": "unknown",
  "env": {
    "LLM_MODEL_NAME": {
      "description": "deepseek-r1:7b-qwen-distill-q6_k_l",
      "required": true
    },
    "LLM_MODEL_PROVIDER": {
      "description": "ollama",
      "required": true
    },
    "LLM_BASE_URL": {
      "description": "http://localhost:11434",
      "required": true
    },
    "LLM_ALLOW_FILE_WRITE": {
      "description": "true",
      "required": true
    },
    "LLM_TIMEOUT_S": {
      "description": "240",
      "required": true
    }
  },
  "name": "MCP LLM"
}